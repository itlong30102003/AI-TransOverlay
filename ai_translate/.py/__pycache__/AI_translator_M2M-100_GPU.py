import cv2
import numpy as np
import mss
import tempfile
import os
import sys
import io
from paddleocr import PaddleOCR
import torch
from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer

# Fix encoding cho Windows console
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# Kh·ªüi t·∫°o OCR
ocr = PaddleOCR(
    use_doc_orientation_classify=False,
    use_doc_unwarping=False,
    use_textline_orientation=False
)

# V√πng m√†n h√¨nh c·∫ßn OCR (full HD screen 1920x1080, b·∫°n ch·ªânh l·∫°i n·∫øu kh√°c)
monitor = {"top": 0, "left": 0, "width": 1920, "height": 1080}

class M2M100Translator:
    def __init__(self, model_name="facebook/m2m100_418M"):
        """
        Initialize M2M-100 translator optimized for RTX 3050
        """
        print(f"üöÄ Loading M2M-100 model: {model_name}")
        print("üéÆ Optimizing for RTX 3050 GPU...")
        
        # Force CUDA if available
        if torch.cuda.is_available():
            self.device = torch.device("cuda")
            print(f"‚úÖ Using GPU: {torch.cuda.get_device_name()}")
            print(f"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**2} MB")
        else:
            self.device = torch.device("cpu")
            print("‚ö†Ô∏è  CUDA not available, using CPU")
        
        try:
            print("1/3 Loading tokenizer...")
            self.tokenizer = M2M100Tokenizer.from_pretrained(model_name)
            
            print("2/3 Loading model with GPU optimization...")
            self.model = M2M100ForConditionalGeneration.from_pretrained(
                model_name,
                torch_dtype=torch.float16,  # Use FP16 for RTX 3050 speed boost
                device_map="auto" if torch.cuda.is_available() else None,
                low_cpu_mem_usage=True
            )
            
            print("3/3 Moving to GPU...")
            if not hasattr(self.model, 'device') or self.model.device != self.device:
                self.model.to(self.device)
            
            self.model.eval()
            
            # Warm up GPU
            print("üî• Warming up GPU...")
            self._warmup_gpu()
            
            print("üéâ M2M-100 ready with GPU acceleration!")
            
        except Exception as e:
            print(f"‚ùå Error loading M2M-100: {e}")
            raise
    
    def _warmup_gpu(self):
        """Warm up GPU with dummy translation"""
        try:
            dummy_text = "Hello"
            self.tokenizer.src_lang = "en"
            encoded = self.tokenizer(dummy_text, return_tensors="pt").to(self.device)
            
            with torch.no_grad():
                _ = self.model.generate(
                    **encoded,
                    forced_bos_token_id=self.tokenizer.get_lang_id("vi"),
                    max_length=10,
                    num_beams=1
                )
            print("‚úÖ GPU warmup completed")
        except:
            print("‚ö†Ô∏è  GPU warmup failed, but model should still work")
    
    def translate_text(self, text, source_lang="en", target_lang="vi"):
        """Fast GPU-accelerated translation"""
        if not text or not text.strip():
            return ""
            
        text_clean = text.strip()
        
        # Skip very short text
        if len(text_clean) < 2:
            return ""
            
        # Skip if not English (quick check)
        if not self.is_likely_english(text_clean):
            return ""
            
        try:
            # Set source language
            self.tokenizer.src_lang = source_lang
            
            # Tokenize and move to GPU
            encoded = self.tokenizer(
                text_clean, 
                return_tensors="pt", 
                padding=True, 
                truncation=True, 
                max_length=100  # Shorter for real-time performance
            ).to(self.device)
            
            # GPU-accelerated generation
            with torch.no_grad():
                generated_tokens = self.model.generate(
                    **encoded,
                    forced_bos_token_id=self.tokenizer.get_lang_id(target_lang),
                    max_length=120,
                    num_beams=1,        # Faster single beam
                    do_sample=False,
                    early_stopping=True,
                    pad_token_id=self.tokenizer.pad_token_id,
                    use_cache=True      # Use KV cache for speed
                )
            
            # Decode result
            translated = self.tokenizer.batch_decode(
                generated_tokens, 
                skip_special_tokens=True
            )[0].strip()
            
            # Return only if translation is different and valid
            if translated and translated.lower() != text_clean.lower():
                return translated
            else:
                return self.fallback_translate(text_clean)
                
        except Exception as e:
            print(f"üîß Translation error: {e}")
            return self.fallback_translate(text_clean)
    
    def is_likely_english(self, text):
        """Check if text is likely English"""
        if not text:
            return False
            
        # Count ASCII alphabetic characters
        ascii_alpha = sum(1 for c in text if c.isascii() and c.isalpha())
        total_alpha = sum(1 for c in text if c.isalpha())
        
        if total_alpha == 0:
            return False
            
        # If > 80% ASCII letters, likely English
        return ascii_alpha / total_alpha > 0.8
    
    def clean_translation(self, translation, original):
        """Clean up M2M-100 translation output"""
        if not translation:
            return original
            
        translation = translation.strip()
        
        # Remove if translation is identical to original
        if translation.lower() == original.lower():
            return self.fallback_translate(original)
            
        # Remove if translation is suspiciously long
        if len(translation) > len(original) * 2.5:
            return self.fallback_translate(original)
            
        return translation
    
    def fallback_translate(self, text):
        """Simple fallback translation"""
        translations = {
            "hello": "xin ch√†o", "world": "th·∫ø gi·ªõi", "good": "t·ªët",
            "morning": "bu·ªïi s√°ng", "evening": "bu·ªïi t·ªëi", "night": "ƒë√™m",
            "thank you": "c·∫£m ∆°n", "thanks": "c·∫£m ∆°n", "please": "xin",
            "apple": "Apple", "macbook": "MacBook", "iphone": "iPhone",
            "discount": "gi·∫£m gi√°", "sale": "khuy·∫øn m√£i", "price": "gi√°",
            "buy": "mua", "shop": "c·ª≠a h√†ng", "free": "mi·ªÖn ph√≠",
            "new": "m·ªõi", "hot": "n√≥ng", "menu": "th·ª±c ƒë∆°n",
            "login": "ƒëƒÉng nh·∫≠p", "password": "m·∫≠t kh·∫©u", "email": "email",
            "search": "t√¨m ki·∫øm", "home": "trang ch·ªß", "help": "tr·ª£ gi√∫p",
            "settings": "c√†i ƒë·∫∑t", "profile": "h·ªì s∆°", "account": "t√†i kho·∫£n"
        }
        
        text_lower = text.lower().strip()
        
        # Exact match
        if text_lower in translations:
            return translations[text_lower]
            
        # Partial match
        for en, vi in translations.items():
            if en in text_lower:
                return text_lower.replace(en, vi)
                
        return f"[{text}]"  # Return original with brackets if no translation

# Kh·ªüi t·∫°o M2M-100 translator - Th·ª≠ model nh·ªè h∆°n n·∫øu b·ªã hang
print("Initializing M2M-100 Translator...")
try:
    # Th·ª≠ model nh·ªè nh·∫•t tr∆∞·ªõc
    ai_translator = M2M100Translator(model_name="facebook/m2m100_418M")
except Exception as e:
    print(f"‚ùå M2M-100 failed: {e}")
    print("üîÑ Falling back to basic translator...")
    
    # Fallback translator n·∫øu M2M-100 fail
    class BasicTranslator:
        def translate_text(self, text):
            translations = {
                "hello": "xin ch√†o", "world": "th·∫ø gi·ªõi", "good": "t·ªët",
                "morning": "bu·ªïi s√°ng", "thank you": "c·∫£m ∆°n", 
                "apple": "Apple", "macbook": "MacBook"
            }
            text_lower = text.lower()
            for en, vi in translations.items():
                if en in text_lower:
                    return text_lower.replace(en, vi)
            return f"[{text}]"
    
    ai_translator = BasicTranslator()

def overlay_translate():
    with mss.mss() as sct:
        while True:
            try:
                # Ch·ª•p m√†n h√¨nh
                screenshot = sct.grab(monitor)
                
                # L∆∞u screenshot t·∫°m th·ªùi ƒë·ªÉ OCR ƒë·ªçc
                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
                    temp_path = temp_file.name
                    mss.tools.to_png(screenshot.rgb, screenshot.size, output=temp_path)
                
                # OCR predict t·ª´ file
                results = ocr.predict(temp_path)
                
                # X√≥a file t·∫°m
                os.unlink(temp_path)
                
                # Chuy·ªÉn screenshot th√†nh frame ƒë·ªÉ hi·ªÉn th·ªã
                frame = np.array(screenshot)
                frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)
                
                # Debug: In ra c·∫•u tr√∫c k·∫øt qu·∫£
                print(f"Results type: {type(results)}")
                
                # X·ª≠ l√Ω k·∫øt qu·∫£ OCR
                if results:
                    for i, res in enumerate(results):
                        print(f"Processing result {i}")
                        
                        # Th·ª≠ truy c·∫≠p theo c√°c c√°ch kh√°c nhau
                        ocr_data = None
                        if hasattr(res, 'res'):
                            print("Found res attribute")
                            ocr_data = res.res
                        elif isinstance(res, dict) and 'res' in res:
                            print("Found res key in dict")
                            ocr_data = res['res']
                        elif isinstance(res, dict):
                            print("Direct dict access")
                            ocr_data = res
                        
                        if ocr_data and isinstance(ocr_data, dict):
                            texts = ocr_data.get('rec_texts', [])
                            scores = ocr_data.get('rec_scores', [])
                            boxes = ocr_data.get('rec_boxes', [])
                            
                            print(f"Found {len(texts)} texts")
                            
                            # V·∫Ω box + d·ªãch
                            for text, confidence, box in zip(texts, scores, boxes):
                                if not text.strip() or confidence < 0.5:
                                    continue
                                
                                try:
                                    # D·ªãch b·∫±ng AI
                                    translated = ai_translator.translate_text(text)
                                    
                                    # Ch·ªâ hi·ªÉn th·ªã n·∫øu c√≥ b·∫£n d·ªãch
                                    if not translated or translated == text or translated.startswith('['):
                                        continue
                                    
                                    # L·∫•y t·ªça ƒë·ªô t·ª´ rec_boxes
                                    x1, y1, x2, y2 = map(int, box)
                                    
                                    # ƒê·∫£m b·∫£o t·ªça ƒë·ªô h·ª£p l·ªá
                                    height, width = frame.shape[:2]
                                    x1, y1 = max(0, x1), max(25, y1)
                                    x2, y2 = min(width, x2), min(height, y2)
                                    
                                    # V·∫Ω n·ªÅn ƒëen m·ªù cho text d·ªãch
                                    overlay = frame.copy()
                                    
                                    # T√≠nh to√°n k√≠ch th∆∞·ªõc text ƒë·ªÉ v·∫Ω n·ªÅn v·ª´a ƒë·ªß
                                    font_scale = 0.7
                                    thickness = 2
                                    (text_width, text_height), baseline = cv2.getTextSize(
                                        translated[:60], cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness
                                    )
                                    
                                    # V·∫Ω n·ªÅn ƒëen v·ªõi padding
                                    padding = 5
                                    bg_x1 = x1 - padding
                                    bg_y1 = y1 - text_height - baseline - padding
                                    bg_x2 = x1 + text_width + padding
                                    bg_y2 = y1 + padding
                                    
                                    cv2.rectangle(overlay, (bg_x1, bg_y1), (bg_x2, bg_y2), (0, 0, 0), -1)
                                    cv2.addWeighted(overlay, 0.8, frame, 0.2, 0, frame)
                                    
                                    # V·∫Ω CH·ªà text d·ªãch ti·∫øng Vi·ªát (m√†u xanh l√° c√¢y s√°ng)
                                    cv2.putText(frame, translated[:60], (x1, y1-baseline),
                                               cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 100), thickness)
                                    
                                    # Debug console - ch·ªâ in n·∫øu d·ªãch th√†nh c√¥ng
                                    try:
                                        print(f"‚úÖ {text} ‚Üí {translated}")
                                    except UnicodeEncodeError:
                                        print(f"‚úÖ Translation successful")
                                
                                except Exception as translate_error:
                                    # Im l·∫∑ng, kh√¥ng in l·ªói ƒë·ªÉ tr√°nh spam console
                                    continue
                
                # Hi·ªÉn th·ªã overlay
                cv2.imshow("AI Overlay Translate", frame)
                
                # Tho√°t b·∫±ng ph√≠m q
                if cv2.waitKey(1) & 0xFF == ord("q"):
                    break
                    
            except Exception as e:
                print(f"Error in main loop: {e}")
                continue
        
        cv2.destroyAllWindows()

if __name__ == "__main__":
    print("üöÄ Starting GPU-Accelerated AI Overlay Translator...")
    print("üéÆ Optimized for RTX 3050")
    print("üáªüá≥ Vietnamese-only translation overlay")
    print("‚ö° Press 'q' to quit")
    print("=" * 50)
    overlay_translate()